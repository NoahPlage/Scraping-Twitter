{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d35b179",
   "metadata": {},
   "source": [
    "# Libraries Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21f0b4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIBRARIES IMPORT\n",
    "\n",
    "# for working with dataframes, CSV\n",
    "import pandas as pd\n",
    "\n",
    "# for working with twitter API\n",
    "import tweepy\n",
    "\n",
    "# for working with wrapping python codes into SQL queries\n",
    "import sqlalchemy as db\n",
    "\n",
    "# for getting current date and time for CSV file creation\n",
    "from datetime import datetime\n",
    "\n",
    "# for keeping credentials out of sight\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# for sentiment analysis\n",
    "from textblob import TextBlob\n",
    "\n",
    "# for stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "import itertools\n",
    "import collections\n",
    "\n",
    "# For generating word cloud\n",
    "from wordcloud import WordCloud\n",
    "import numpy as np\n",
    "\n",
    "# for plotting wordcloud and sentiments analysis pie chart\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e708269",
   "metadata": {},
   "source": [
    "# Credentials and Authorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ff5a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish working directory path\n",
    "# getcwd() returns current working directory\n",
    "wdir_path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772afc65",
   "metadata": {},
   "source": [
    "### Twitter Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11eb122f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a \"twitter-keys.env\" file under the script working directory\n",
    "# fill in personal api keys and access tokens and save\n",
    "\n",
    "twitter_path = os.path.join(wdir_path, \"twitter-keys.env\") # absolute path of \"twitter-keys.env\"\n",
    "# load the credentials into os environment \n",
    "load_dotenv(twitter_path)\n",
    "#check if credentials loaded successfully\n",
    "os.environ\n",
    "\n",
    "\n",
    "# Credentials obtained from twitter developer account to access API\n",
    "# getting api_keys & access_tokens from \"twitter-keys.env\"\n",
    "consumer_key = os.getenv(\"consumer_key\")\n",
    "consumer_secret = os.getenv(\"consumer_secret\")\n",
    "access_key = os.getenv(\"access_key\")\n",
    "access_secret = os.getenv(\"access_secret\")\n",
    "\n",
    "# setup Twitter API connection details\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_key, access_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea039b",
   "metadata": {},
   "source": [
    "### SQL Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19c10f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a \"sql-keys.env\" file under the script working directory\n",
    "# fill in personal api keys and access tokens and save\n",
    "sql_path = os.path.join(wdir_path, \"sql-keys.env\") # absolute path of \"sql-keys.env\"\n",
    "# load the credentials into os environment \n",
    "load_dotenv(sql_path)\n",
    "#check if credentials loaded successfully\n",
    "os.environ\n",
    "\n",
    "# getting credentials information from \"sql-keys.env\"\n",
    "user = os.getenv(\"dbUser\")\n",
    "password = os.getenv(\"dbPwd\")\n",
    "hostname = os.getenv(\"dbHost\")\n",
    "port_no = os.getenv(\"dbPort\")\n",
    "db_name = os.getenv(\"dbName\")\n",
    "\n",
    "# setup connection engine details\n",
    "engine = db.create_engine(f\"postgresql://{user}:{password}@{hostname}:{port_no}/{db_name}\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c00856f",
   "metadata": {},
   "source": [
    "# Create Table in PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c56cbd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 table(s) have been created in PostgreSQL.\n"
     ]
    }
   ],
   "source": [
    "# Create connection engine\n",
    "conn = engine.raw_connection()\n",
    "\n",
    "# Create new tables in PostgreSQL\n",
    "commands = (\"\"\"CREATE TABLE IF NOT EXISTS twitterDatabase (tweet_id BIGINT PRIMARY KEY,\n",
    "                                                           username VARCHAR(15),\n",
    "                                                           display_name TEXT,\n",
    "                                                           location TEXT,\n",
    "                                                           followers_count INTEGER,\n",
    "                                                           following_count INTEGER,\n",
    "                                                           tweet_text TEXT,\n",
    "                                                           hashtags TEXT,\n",
    "                                                           polarity NUMERIC(3,2),\n",
    "                                                           subjectivity NUMERIC(3,2));\"\"\")\n",
    "\n",
    "# Initialize connection to PostgreSQL\n",
    "cur = conn.cursor()\n",
    "table_count = 0\n",
    "\n",
    "# Create cursor to execute SQL commands\n",
    "cur.execute(commands)\n",
    "table_count += 1\n",
    "\n",
    "# Close communication with server\n",
    "conn.commit()\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "print(str(table_count),\"table(s) have been created in PostgreSQL.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebb92a1",
   "metadata": {},
   "source": [
    "# Data Extraction\n",
    "\n",
    "Creation of queries using Tweepy API\n",
    "\n",
    "Function is focused on completing the query then providing a CSV file of that query using pandas\n",
    "\n",
    "And then inserting the data directly into PostgreSQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bbb2832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to display data of each tweet\n",
    "def printtweetdata(n, ith_tweet):\n",
    "        print()\n",
    "        print(f\"====Tweet {n}====\")\n",
    "        print(f\"Tweet ID:{ith_tweet[0]}\")\n",
    "        print(f\"Userame:{ith_tweet[1]}\")\n",
    "        print(f\"Display Name:{ith_tweet[2]}\")\n",
    "        print(f\"Location:{ith_tweet[3]}\")\n",
    "        print(f\"Follower Count:{ith_tweet[4]}\")\n",
    "        print(f\"Following Count:{ith_tweet[5]}\")\n",
    "        print(f\"Tweet Text:{ith_tweet[6]}\")\n",
    "        print(f\"Hashtags Used:{ith_tweet[7]}\")\n",
    "        print(f\"Polarity:{ith_tweet[8]}\")\n",
    "        print(f\"Subjectivity:{ith_tweet[9]}\")\n",
    "\n",
    "# function to perform data extraction\n",
    "def scrape(words, numtweet):\n",
    "\n",
    "        # Creating DataFrame using pandas\n",
    "        tweetsDF = pd.DataFrame(columns=[\"tweet_id\",\n",
    "                                   \"username\",\n",
    "                                   \"display_name\",\n",
    "                                   \"location\",\n",
    "                                   \"followers\",\n",
    "                                   \"following\",\n",
    "                                   \"text\",\n",
    "                                   \"hashtags\",\n",
    "                                   'polarity',\n",
    "                                   'subjectivity'])\n",
    "\n",
    "        # We are using .Cursor() to search through twitter for the required tweets.\n",
    "        # The number of tweets can be restricted using .items(number of tweets)\n",
    "        if inp == \"1\": # if user input to search using hashtag\n",
    "            tweets = tweepy.Cursor(api.search_tweets,\n",
    "                                   words,\n",
    "                                   lang=\"en\",\n",
    "                                   tweet_mode=\"extended\").items(numtweet)\n",
    "        elif inp == \"2\": # if user input to search using username\n",
    "            tweets = tweepy.Cursor(api.user_timeline,\n",
    "                                   screen_name=words,\n",
    "                                   tweet_mode=\"extended\").items(numtweet)\n",
    "                \n",
    "        \n",
    "        # .Cursor() returns an iterable object.\n",
    "        # Each item in the iterator has various attributes\n",
    "        # that you can access to get information about each tweet\n",
    "        list_tweets = [tweet for tweet in tweets]\n",
    "        \n",
    "        # we will iterate over each tweet in the list for extracting information about each tweet\n",
    "        val = []\n",
    "        for i, tweet in enumerate(list_tweets, 1):\n",
    "            tweet_id = tweet.id\n",
    "            username = tweet.user.screen_name\n",
    "            display_name = tweet.user.name\n",
    "            location = tweet.user.location\n",
    "            followers = tweet.user.followers_count\n",
    "            following = tweet.user.friends_count\n",
    "            hashtags = tweet.entities[\"hashtags\"]\n",
    "            \n",
    "            # Retweets can be distinguished by a retweeted_status attribute,\n",
    "            # in case it is an invalid reference, except block will be executed\n",
    "            try:\n",
    "                text = tweet.retweeted_status.full_text\n",
    "            except AttributeError:\n",
    "                text = tweet.full_text\n",
    "            \n",
    "            # Sentiment analysis\n",
    "            polarity = round(TextBlob(text).sentiment[0], 2)\n",
    "            subjectivity = round(TextBlob(text).sentiment[1], 2)            \n",
    "            \n",
    "            # extracting all hashtags in the tweet\n",
    "            # because there may be multiple hashtags in a tweet\n",
    "            hashtext = list()            \n",
    "            for j in range(0, len(hashtags)):\n",
    "                hashtext.append(hashtags[j][\"text\"])\n",
    "                \n",
    "            # Here we are appending all the extracted information in the DataFrame\n",
    "            ith_tweet = [tweet_id, username,\n",
    "                         display_name, location,\n",
    "                         followers, following,\n",
    "                         text, hashtext,\n",
    "                         polarity, subjectivity]\n",
    "            tweetsDF.loc[len(tweetsDF)] = ith_tweet\n",
    "\n",
    "            # Function call to print tweet data on screen\n",
    "            ### printtweetdata(i, ith_tweet)\n",
    "            val.append(ith_tweet)\n",
    "        \n",
    "        # call word_cloud\n",
    "        word_cloud(tweetsDF)\n",
    "        \n",
    "        # we will save our database as a CSV file.\n",
    "        # depending on user's input to search by hashtag or username\n",
    "        # CSV filename generated will be different\n",
    "        if inp == \"1\": # if user input to search using hashtag\n",
    "            tweetsDF.to_csv(\"hashtag-{}-tweets_{}.csv\".format(words, datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")), sep=\",\", index=False)\n",
    "        elif inp == \"2\": # if user input to search using username\n",
    "            tweetsDF.to_csv('{}-tweets_{}.csv'.format(username, datetime.now().strftime(\"%Y-%m-%d_%H%M%S\")), sep=',', index=False)\n",
    "        \n",
    "\n",
    "        # SQL command to insert scrapped tweet data into PostgreSQL database\n",
    "        sql = \"\"\"\n",
    "        INSERT INTO twitterDatabase(tweet_id, username, display_name, location, followers_count, following_count,\n",
    "        tweet_text, hashtags, polarity, subjectivity)\n",
    "        VALUES(%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\n",
    "        ) ON CONFLICT(tweet_id) DO NOTHING\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create connection engine\n",
    "        conn = engine.raw_connection()\n",
    "        \n",
    "        # Initialize connection to PostgreSQL\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # Create cursor to execute SQL commands\n",
    "        cur.executemany(sql, val)\n",
    "        \n",
    "        # print message when scrape is successful\n",
    "        print(\"\\nScraping has completed!\")\n",
    "\n",
    "        # Close communication with server\n",
    "        conn.commit()\n",
    "        cur.close()\n",
    "        conn.close()      \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1800400a",
   "metadata": {},
   "source": [
    "# Sentimental Analysis - Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9bba1f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_cloud(tweetsDF):\n",
    "    # removal of stopwords\n",
    "    words_in_tweet = [tweet.lower().split() for tweet in tweetsDF.text] # creating list of individual word from all tweets\n",
    "    stop_words = set(stopwords.words('english')) # initialising stopwords / commonly used words\n",
    "    tweets_nsw = [[word for word in tweet_words if word not in stop_words]\n",
    "                    for tweet_words in words_in_tweet]  # removing stopwords from list of individual words\n",
    "    all_words = list(itertools.chain(*tweets_nsw)) # flatten into 1 list\n",
    "\n",
    "    # Create counter\n",
    "    counts_words = collections.Counter(all_words)\n",
    "\n",
    "    # Generate wordcloud\n",
    "    wordcloud = WordCloud(font_step=1,\n",
    "                            stopwords=stop_words, # removes any specified unwanted words\n",
    "                            background_color='white').generate(' '.join(str(w) for w in all_words)) # collapse list to get string\n",
    "\n",
    "    # Displays the image\n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear') # interpolation used to display smoother image\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    # Generate a dove word cloud image\n",
    "    dove_mask = np.array(Image.open(\"dove.jpg\")) # Ref: https://python-course.eu/applications-python/python-wordcloud-tutorial.php\n",
    "    wordcloud = WordCloud(font_step=1, \n",
    "                    stopwords=stop_words,\n",
    "                    collocations=False,\n",
    "                    background_color='white',\n",
    "                    mask=dove_mask,\n",
    "                    contour_width=7, \n",
    "                    contour_color='darkgreen').generate(' '.join(str(v) for v in all_words))\n",
    "    \n",
    "    # Display dove image & store to file\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.savefig(\"dove_out.jpg\", format=\"jpg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7859510f",
   "metadata": {},
   "source": [
    "# Sentimental Analysis - Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c799e91d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m tweets_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msentiment\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mtweets_df\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(sentiment_cal)\n\u001b[0;32m      9\u001b[0m tweets_filter \u001b[38;5;241m=\u001b[39m tweets_df[tweets_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mcontains(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStandWithUkraine\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStopRussia\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[0;32m     10\u001b[0m tweets_filter\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tweets_df' is not defined"
     ]
    }
   ],
   "source": [
    "def sentiment_cal(text):\n",
    "    try:\n",
    "        return TextBlob(text).sentiment\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "tweets_df['sentiment'] = tweets_df['tweet'].apply(sentiment_cal)\n",
    "\n",
    "tweets_filter = tweets_df[tweets_df['tweet'].str.contains('StandWithUkraine', 'StopRussia')]\n",
    "tweets_filter   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6507e8f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'getcontext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [17]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m neu_tweets \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m   \u001b[38;5;66;03m#count of neutral tweets\u001b[39;00m\n\u001b[0;32m      4\u001b[0m total_tweets \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m#total count of tweets\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[43mgetcontext\u001b[49m()\u001b[38;5;241m.\u001b[39mprec\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweets_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtweet\u001b[39m\u001b[38;5;124m'\u001b[39m]:\n\u001b[0;32m      9\u001b[0m         total_tweets \u001b[38;5;241m=\u001b[39m total_tweets \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'getcontext' is not defined"
     ]
    }
   ],
   "source": [
    "pos_tweets = 0   #count of positive tweets\n",
    "neg_tweets = 0   #count of negative tweets\n",
    "neu_tweets = 0   #count of neutral tweets\n",
    "total_tweets = 0 #total count of tweets\n",
    "\n",
    "getcontext().prec=3\n",
    "\n",
    "for tweet in tweets_df['tweet']:\n",
    "        total_tweets = total_tweets + 1\n",
    "        if TextBlob(tweet).sentiment.polarity > 0:\n",
    "            pos_tweets = pos_tweets + 1\n",
    "        if TextBlob(tweet).sentiment.polarity == 0:\n",
    "            neu_tweets = neu_tweets + 1\n",
    "        if TextBlob(tweet).sentiment.polarity < 0:\n",
    "            neg_tweets = neg_tweets + 1\n",
    "\n",
    "tweets_count = [pos_tweets,\n",
    "                 neg_tweets,\n",
    "                 neu_tweets]\n",
    "\n",
    "labels = ['Positive ' + str(Decimal((pos_tweets /total_tweets)) * 100) + ' %',\n",
    "         'Negative ' + str(Decimal((neg_tweets / total_tweets)) * 100) + ' %',\n",
    "         'Neutral ' + str(Decimal((neu_tweets / total_tweets)) * 100) + ' %']\n",
    "plt.pie( tweets_count,\n",
    "labels=labels,\n",
    "colors=['green','orange','blue']\n",
    ")\n",
    "plt.show()\n",
    "\n",
    "print(tweets_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9b0fb6",
   "metadata": {},
   "source": [
    "# User Search Query\n",
    "\n",
    "Querying user if they want to search by hashtag or username\n",
    "\n",
    "Then querying for user's input based on their choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b7b55e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Do you want to:\n",
      "1) Search by a hashtag, or\n",
      "2) Search by a username?\n",
      "1\n",
      "Enter Twitter HashTag to search for.\n",
      "StandWithUkraine\n",
      "\n",
      "Loading, please wait......\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'TextBlob' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou must choose between 1 or 2\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m one_or_two()\n\u001b[1;32m---> 39\u001b[0m \u001b[43mone_or_two\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mone_or_two\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inp \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;66;03m# if user choose to search by hashtag\u001b[39;00m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter Twitter HashTag to search for.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m     \u001b[43msearch_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inp \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;66;03m# if user to choose to search by username\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter Twitter Username to search for.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36msearch_input\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m numtweet \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mLoading, please wait......\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mscrape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwords\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumtweet\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36mscrape\u001b[1;34m(words, numtweet)\u001b[0m\n\u001b[0;32m     65\u001b[0m     text \u001b[38;5;241m=\u001b[39m tweet\u001b[38;5;241m.\u001b[39mfull_text\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# Sentiment analysis\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m polarity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(\u001b[43mTextBlob\u001b[49m(text)\u001b[38;5;241m.\u001b[39msentiment[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     69\u001b[0m subjectivity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mround\u001b[39m(TextBlob(text)\u001b[38;5;241m.\u001b[39msentiment[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m2\u001b[39m)            \n\u001b[0;32m     71\u001b[0m \u001b[38;5;66;03m# extracting all hashtags in the tweet\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m# because there may be multiple hashtags in a tweet\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'TextBlob' is not defined"
     ]
    }
   ],
   "source": [
    "# function for user search query\n",
    "def search_input():\n",
    "\n",
    "    # To make sure user enters only valid inputs; must be alphanumeric.\n",
    "    while True:\n",
    "        try:\n",
    "            words = input()\n",
    "            # If input is empty\n",
    "            if not words:\n",
    "                raise ValueError(\"You did not enter anything. Please try again.\")\n",
    "            # If input does not contain only alphanumeric.\n",
    "            elif not words.isalnum():\n",
    "                raise ValueError(\"Only alphanumeric allowed. Please try again.\")\n",
    "            break\n",
    "        except ValueError as e: # to catch any other errors.\n",
    "            print(e)\n",
    "\n",
    "    numtweet = 100\n",
    "\n",
    "    print(\"\\nLoading, please wait......\")\n",
    "    \n",
    "    scrape(words, numtweet)\n",
    "    \n",
    "# function to query if user wants to search by hashtag or username\n",
    "def one_or_two():\n",
    "    # asking user how they want to search\n",
    "    print(\"Do you want to:\\n1) Search by a hashtag, or\\n2) Search by a username?\")\n",
    "    global inp # declaring this inp as global so it can be used to check user's input in other functions\n",
    "    inp = input()\n",
    "    if inp == \"1\": # if user choose to search by hashtag\n",
    "        print(\"Enter Twitter HashTag to search for.\")\n",
    "        search_input()\n",
    "    elif inp == \"2\": # if user to choose to search by username\n",
    "        print(\"Enter Twitter Username to search for.\")\n",
    "        search_input()\n",
    "    else: # if user did not input 1 or 2\n",
    "        print(\"You must choose between 1 or 2\\n\")\n",
    "        return one_or_two()\n",
    "one_or_two()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731cb8f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
